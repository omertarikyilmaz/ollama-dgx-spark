# Ollama Model Configuration
OLLAMA_MODEL=qwen2.5:32b-instruct-q4_K_M

# KV Cache Settings (q4_0 = fastest, q8_0 = balanced, f16 = best quality)
OLLAMA_KV_CACHE_TYPE=q8_0

# Parallel requests (increase for more throughput)
OLLAMA_NUM_PARALLEL=4

# Keep model in memory (longer = faster for repeated requests)
OLLAMA_KEEP_ALIVE=10m
